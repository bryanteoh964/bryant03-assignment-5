{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "h2KR3MweS11O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qIgaEz-5S11R"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        if not isinstance(k, int) or k <= 0:\n",
        "            raise ValueError(\"k must be a positive integer\")\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y.astype(int)\n",
        "\n",
        "    def predict(self, X, batch_size=1000):\n",
        "        return self._predict_proba(X, batch_size).argmax(axis=1)\n",
        "\n",
        "    def predict_proba(self, X, batch_size=1000):\n",
        "        return self._predict_proba(X, batch_size)\n",
        "\n",
        "    def _predict_proba(self, X, batch_size=1000):\n",
        "        n_samples = X.shape[0]\n",
        "        n_classes = len(np.unique(self.y_train))\n",
        "        y_pred_proba = np.zeros((n_samples, n_classes))\n",
        "\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            batch = X[i:i+batch_size]\n",
        "            if self.distance_metric == 'euclidean':\n",
        "                distances = np.sqrt(((batch[:, np.newaxis, :] - self.X_train[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
        "            elif self.distance_metric == 'manhattan':\n",
        "                distances = np.abs(batch[:, np.newaxis, :] - self.X_train[np.newaxis, :, :]).sum(axis=2)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid distance metric\")\n",
        "\n",
        "            k = min(self.k, self.X_train.shape[0])\n",
        "            k_indices = np.argpartition(distances, k, axis=1)[:, :k]\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "\n",
        "            for j, label in enumerate(k_nearest_labels):\n",
        "                y_pred_proba[i+j] = np.bincount(label, minlength=n_classes) / k\n",
        "\n",
        "        return y_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5JhruLyiS11S"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Handle missing values\n",
        "    train_data = train_data.dropna()\n",
        "    test_data = test_data.dropna()\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_columns = ['Geography', 'Gender']\n",
        "    for column in categorical_columns:\n",
        "        train_data[column] = pd.Categorical(train_data[column]).codes\n",
        "        test_data[column] = pd.Categorical(test_data[column]).codes\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train = train_data.drop(['Exited', 'id', 'Surname'], axis=1)\n",
        "    y_train = train_data['Exited'].astype(int)\n",
        "    X_test = test_data.drop(['id', 'Surname'], axis=1)\n",
        "\n",
        "    # Apply feature scaling\n",
        "    X_train, X_test = feature_scaling(X_train, X_test)\n",
        "\n",
        "    return X_train, y_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_scaling(X_train, X_test):\n",
        "    # Min-Max scaling\n",
        "    min_vals = X_train.min()\n",
        "    max_vals = X_train.max()\n",
        "    X_train_scaled = (X_train - min_vals) / (max_vals - min_vals)\n",
        "    X_test_scaled = (X_test - min_vals) / (max_vals - min_vals)\n",
        "    return X_train_scaled, X_test_scaled"
      ],
      "metadata": {
        "id": "1CTlJ-OJbn8d"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "HnD2HMcCS11T"
      },
      "outputs": [],
      "source": [
        "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    n = len(X)\n",
        "    n_test = int(n * test_size)\n",
        "    indices = np.random.permutation(n)\n",
        "    test_indices = indices[:n_test]\n",
        "    train_indices = indices[n_test:]\n",
        "\n",
        "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
        "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "H0g_HIrzS11T"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    fold_size = len(X) // n_splits\n",
        "    scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        start = i * fold_size\n",
        "        end = (i + 1) * fold_size if i < n_splits - 1 else len(X)\n",
        "        test_indices = indices[start:end]\n",
        "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
        "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "        knn.fit(X_train.values, y_train.values)\n",
        "        y_pred = knn.predict(X_test.values)\n",
        "        score = np.mean(y_pred == y_test)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores), np.std(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lgLOqbD2S11V"
      },
      "outputs": [],
      "source": [
        "def evaluate_knn_with_different_k(X_train, y_train, X_val, y_val, k_values, distance_metrics):\n",
        "    best_accuracy = 0\n",
        "    best_k = 0\n",
        "    best_metric = ''\n",
        "\n",
        "    for metric in distance_metrics:\n",
        "        for k in k_values:\n",
        "            knn = KNN(k=k, distance_metric=metric)\n",
        "            knn.fit(X_train, y_train)\n",
        "            val_predictions = knn.predict(X_val)\n",
        "            accuracy = np.mean(val_predictions == y_val)\n",
        "            print(f\"Validation Accuracy for k={k}, metric={metric}: {accuracy:.4f}\")\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_k = k\n",
        "                best_metric = metric\n",
        "\n",
        "    print(f\"\\nBest k: {best_k}, Best metric: {best_metric} with accuracy: {best_accuracy:.4f}\")\n",
        "    return best_k, best_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uk4m5rcfS11U"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "X_train, y_train, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Split the training data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays for faster computation\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_val = X_val.values\n",
        "y_val = y_val.values\n",
        "X_test = X_test.values"
      ],
      "metadata": {
        "id": "SeVouBqNTur8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "k_values = [12, 13, 14, 15, 16, 17]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "best_k, best_metric = evaluate_knn_with_different_k(X_train, y_train, X_val, y_val, k_values, distance_metrics)\n",
        "\n",
        "# Train with best parameters\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFJ-0zpb5mP",
        "outputId": "d74c20a9-18ef-4176-8762-b9487e132635"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy for k=12, metric=euclidean: 0.8637\n",
            "Validation Accuracy for k=13, metric=euclidean: 0.8677\n",
            "Validation Accuracy for k=14, metric=euclidean: 0.8647\n",
            "Validation Accuracy for k=15, metric=euclidean: 0.8637\n",
            "Validation Accuracy for k=16, metric=euclidean: 0.8630\n",
            "Validation Accuracy for k=17, metric=euclidean: 0.8637\n",
            "Validation Accuracy for k=12, metric=manhattan: 0.8630\n",
            "Validation Accuracy for k=13, metric=manhattan: 0.8643\n",
            "Validation Accuracy for k=14, metric=manhattan: 0.8660\n",
            "Validation Accuracy for k=15, metric=manhattan: 0.8647\n",
            "Validation Accuracy for k=16, metric=manhattan: 0.8607\n",
            "Validation Accuracy for k=17, metric=manhattan: 0.8643\n",
            "\n",
            "Best k: 13, Best metric: euclidean with accuracy: 0.8677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wLehAuaS11V",
        "outputId": "a5e1d342-8256-4cc9-e34f-936c2907cdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation score: 0.8692 (+/- 0.0068)\n"
          ]
        }
      ],
      "source": [
        "# Perform cross-validation\n",
        "cv_score, cv_std = cross_validate(pd.DataFrame(X_train), pd.Series(y_train), knn)\n",
        "print(f\"Cross-validation score: {cv_score:.4f} (+/- {cv_std:.4f})\")\n",
        "\n",
        "# Train on full dataset and make predictions on test set\n",
        "full_X_train = np.vstack((X_train, X_val))\n",
        "full_y_train = np.hstack((y_train, y_val))\n",
        "knn.fit(full_X_train, full_y_train)\n",
        "\n",
        "# Predict probabilities in batches to save memory\n",
        "batch_size = 1000\n",
        "test_predictions_proba = np.zeros((X_test.shape[0], 2))\n",
        "for i in range(0, X_test.shape[0], batch_size):\n",
        "    batch = X_test[i:i+batch_size]\n",
        "    test_predictions_proba[i:i+batch_size] = knn.predict_proba(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_L9X20hS11X",
        "outputId": "4cd77bd8-150b-488c-87eb-80a73f72d215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n"
          ]
        }
      ],
      "source": [
        "# Save test predictions (probabilities for the positive class)\n",
        "submission = pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions_proba[:, 1]})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created: submission.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}